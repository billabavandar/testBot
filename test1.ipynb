{
 "cells": [
  {
   "cell_type": "code",
   "id": "55995f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T10:50:53.729913Z",
     "start_time": "2025-06-04T10:50:53.726014Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from langchain_community.document_loaders import TextLoader # To load our .txt files\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # To split documents\n",
    "from langchain_openai import OpenAIEmbeddings # For creating embeddings\n",
    "from langchain_community.vectorstores import FAISS # The FAISS vector store\n",
    "from langchain_openai import OpenAI # An LLM for Q&A later\n",
    "from langchain.chains import RetrievalQA # The chain for Q&A over retrieved docs"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "712d9ce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T15:48:25.983382Z",
     "start_time": "2025-06-04T15:48:25.977767Z"
    }
   },
   "source": [
    "doc_paths = [\"doc1.txt\", \"doc2.txt\", \"doc3.txt\", \"doc4.txt\"]\n",
    "all_docs = []\n",
    "for path in doc_paths:\n",
    "    # Imagine each docX.txt file exists with the content mentioned above\n",
    "    # For this conceptual example, let's simulate loading:\n",
    "    if path == \"doc1.txt\":\n",
    "        content = \"LangChain is a framework for developing applications powered by large language models. It provides modular components and chains.\"\n",
    "    elif path == \"doc2.txt\":\n",
    "        content = \"Vector databases like FAISS are used to store and search embeddings. Embeddings represent text semantically.\"\n",
    "    elif path == \"doc3.txt\":\n",
    "        content = \"FAISS allows for efficient similarity search. It was developed by Facebook AI.\"\n",
    "    elif path == \"doc4.txt\":\n",
    "        content = \"A key feature of LangChain is its ability to chain calls to LLMs and other tools.\"\n",
    "    else:\n",
    "        content = \"\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T15:51:11.011574Z",
     "start_time": "2025-06-04T15:51:11.006887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "all_docs.append(Document(page_content=content, metadata={\"source\": path}))"
   ],
   "id": "bab4fd371637369e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T15:52:47.691666Z",
     "start_time": "2025-06-04T15:52:47.686116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, #max characters per chunk\n",
    "    chunk_overlap=20 #overlap\n",
    ")\n",
    "split_docs = text_splitter.split_documents(all_docs)"
   ],
   "id": "3db3ff25304a7714",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d16cd7c70af20b3"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
